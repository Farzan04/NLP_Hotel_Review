{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a02e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aba84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db265ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>word_len_review</th>\n",
       "      <th>string_len_review</th>\n",
       "      <th>aaa</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yr</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yunque</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>250</td>\n",
       "      <td>1689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label  word_len_review  string_len_review  aaa  abc  ability  \\\n",
       "0           0      1               87                593  0.0  0.0      0.0   \n",
       "1           1     -1              250               1689  0.0  0.0      0.0   \n",
       "2           2      0              217               1427  0.0  0.0      0.0   \n",
       "3           3      1               89                600  0.0  0.0      0.0   \n",
       "4           4      1              191               1281  0.0  0.0      0.0   \n",
       "\n",
       "   abit  able  abroad  ...  young  younger   yr  yuck  yum  yummy  yunque  \\\n",
       "0   0.0   0.0     0.0  ...    0.0      0.0  0.0   0.0  0.0    0.0     0.0   \n",
       "1   0.0   0.0     0.0  ...    0.0      0.0  0.0   0.0  0.0    0.0     0.0   \n",
       "2   0.0   0.0     0.0  ...    0.0      0.0  0.0   0.0  0.0    0.0     0.0   \n",
       "3   0.0   0.0     0.0  ...    0.0      0.0  0.0   0.0  0.0    0.0     0.0   \n",
       "4   0.0   0.0     0.0  ...    0.0      0.0  0.0   0.0  0.0    0.0     0.0   \n",
       "\n",
       "   zero  zone  zoo  \n",
       "0   0.0   0.0  0.0  \n",
       "1   0.0   0.0  0.0  \n",
       "2   0.0   0.0  0.0  \n",
       "3   0.0   0.0  0.0  \n",
       "4   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 5004 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('model_building_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86208288",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b69f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30952f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mchi2, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maround(fit\u001b[38;5;241m.\u001b[39mscores_, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m scores\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:408\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score function should be a callable, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) was passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func))\n\u001b[0;32m    405\u001b[0m     )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[1;32m--> 408\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_func_ret, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpvalues_ \u001b[38;5;241m=\u001b[39m score_func_ret\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:215\u001b[0m, in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    213\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((X\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;28;01melse\u001b[39;00m X) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput X must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    217\u001b[0m Y \u001b[38;5;241m=\u001b[39m LabelBinarizer()\u001b[38;5;241m.\u001b[39mfit_transform(y)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "model = SelectKBest(score_func=chi2, k='all')\n",
    "fit = model.fit(data.iloc[:,1:], data.iloc[:,0])\n",
    "scores = np.around(fit.scores_, 3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229abdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cols = list(np.where(scores>0.5)[0])\n",
    "idx_cols = [x+1 for x in idx_cols]\n",
    "idx_cols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a117b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.iloc[:,0],data.iloc[:,idx_cols]], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c25ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818b1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6d95a6",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8907628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e46cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228ceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a48562",
   "metadata": {},
   "source": [
    "## 1).Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da867a6",
   "metadata": {},
   "source": [
    "+ Since we are going to use One Vs Rest algorithm, set **multi_class='ovr'**\n",
    "+ Note: since we are using One Vs Rest algorithm we must use **'liblinear' solver** with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ddf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', multi_class='ovr', solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b78371",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c01af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report: \\n',classification_report(y_test, y_test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbc54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e5c6a7",
   "metadata": {},
   "source": [
    "## 2).K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94c109",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Plot\n",
    "acc = []\n",
    "for k in range(1, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train , y_train)\n",
    "    y_predict = knn.predict(X_train)\n",
    "    acc.append(accuracy_score(y_train , y_predict))\n",
    "    \n",
    "plt.plot(range(1, 11), acc)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Neighbour')\n",
    "plt.ylabel('ACCURACY')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter Value\n",
    "kfold = KFold()\n",
    "n_neighbors = np.array(range(1,10))\n",
    "param_grid = {'n_neighbors':n_neighbors}\n",
    "\n",
    "# Hyper parameter tunning using GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = kfold, n_jobs=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb54766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2f25c",
   "metadata": {},
   "source": [
    "### K-NN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef04b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=para['n_neighbors'])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7146b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b53ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06de912a",
   "metadata": {},
   "source": [
    "## 3).Naive Bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04705655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab694a",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter Value\n",
    "kfold = KFold()\n",
    "alpha = np.arange(0.1, 1.1, 0.1)\n",
    "param_grid = {'alpha':alpha}\n",
    "\n",
    "# Hyper parameter tunning using GridSearchCV\n",
    "model = MultinomialNB()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = kfold, n_jobs=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cad232",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3edd5",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=para['alpha'])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6abdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afec9358",
   "metadata": {},
   "source": [
    "## 4). Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65723321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import  DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6172d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "result.mean()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa5b79",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e082aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['entropy','gini'] ,'max_depth': [2,4,6,8,10,12], 'min_samples_split': [2,3,4]}\n",
    "\n",
    "model_test = DecisionTreeClassifier()\n",
    "gcv = GridSearchCV(estimator=model_test,param_grid=params)\n",
    "gcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gcv.best_score_)\n",
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1baea7a",
   "metadata": {},
   "source": [
    "### Decision Tree Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion=para['criterion'], max_depth=para['max_depth'], \n",
    "                               min_samples_split=para['min_samples_split'])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af113572",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557936e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
